{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 1.0.0a0+60e7d04\n",
      "CUDA version: 10.0.130\n",
      "CUDNN version: 7401\n",
      "DISTRIB_DESCRIPTION=\"Ubuntu 16.04.5 LTS\"\r\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "print('torch version:', torch.__version__)\n",
    "print('CUDA version:', torch.version.cuda)\n",
    "print('CUDNN version:', torch.backends.cudnn.version())\n",
    "!tail -n 1 /etc/lsb-release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchBenchmark:\n",
    "    def f(self):\n",
    "        with torch.no_grad():\n",
    "            while True:\n",
    "                self.op(self.dummy)\n",
    "                torch.cuda.synchronize()\n",
    "                yield self.FLOP\n",
    "    \n",
    "    def test(self, tflop=100):\n",
    "        if self.half:\n",
    "            tflop *= 4\n",
    "        sys.stdout.flush()\n",
    "        total = tflop * 1024 ** 4\n",
    "        with tqdm(self.f(), total=total, unit='FLOP', unit_scale=True, unit_divisor=1024) as pbar:\n",
    "            for x in pbar:\n",
    "                if pbar.n + x > total:\n",
    "                    pbar.update(total - pbar.n)\n",
    "                    break\n",
    "                else:\n",
    "                    pbar.update(x)\n",
    "        \n",
    "        mean_speed = pbar.last_print_n / (pbar.last_print_t - pbar.start_t) / (1024 ** 4)\n",
    "        return mean_speed\n",
    "    \n",
    "    def describe(self):\n",
    "        print('Input shape:',self.dummy.shape)\n",
    "        print('Op:', self.op)\n",
    "        print(f'{self.FLOP / (1024 ** 3):.3f}GFLOP')\n",
    "\n",
    "class TorchBenchmarkLinear(TorchBenchmark):\n",
    "    def __init__(self, a, b, c, bias=False, half=False):\n",
    "        super(TorchBenchmarkLinear, self).__init__()\n",
    "        \n",
    "        self.half = half\n",
    "        self.dummy = torch.randn((1, a, b)).cuda()\n",
    "        self.op = torch.nn.Linear(b, c, bias=bias).cuda()\n",
    "        if half:\n",
    "            self.dummy = self.dummy.half()\n",
    "            self.op = self.op.half()\n",
    "        self.FLOP = (b * 2) * a * c\n",
    "\n",
    "class TorchBenchmarkConv2d(TorchBenchmark):\n",
    "    def __init__(self, width, in_channels, out_channels, kernel_size, bias=False, half=False):\n",
    "        super(TorchBenchmarkConv2d, self).__init__()\n",
    "        self.half = half\n",
    "        self.dummy = torch.randn((1, in_channels, width, width)).cuda()\n",
    "        self.op = torch.nn.Conv2d(in_channels, out_channels, kernel_size, bias=bias).cuda()\n",
    "        if half:\n",
    "            self.dummy = self.dummy.half()\n",
    "            self.op = self.op.half()\n",
    "        \n",
    "        width2 = width - kernel_size + 1\n",
    "        self.FLOP = (kernel_size ** 2 * 2 * in_channels) * out_channels * width2 * width2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(device_id=0):\n",
    "    torch.cuda.set_device(device_id)\n",
    "    print(torch.cuda.get_device_properties(device_id))\n",
    "\n",
    "    A = 2**12\n",
    "    bm = TorchBenchmarkLinear(A, A, A)\n",
    "    fp32_speed = bm.test()\n",
    "    fp16_speed = TorchBenchmarkLinear(A, A, A, half=True).test()\n",
    "    bm.describe()\n",
    "    print(f'Speedup ratio: {fp16_speed / fp32_speed * 100:.2f}%')\n",
    "    \n",
    "    W = 2 ** 8\n",
    "    C = 2 ** 8\n",
    "    K = 2 ** 3\n",
    "    bm = TorchBenchmarkConv2d(W, C, C, K, half=False)\n",
    "    fp32_speed = bm.test()\n",
    "    fp16_speed = TorchBenchmarkConv2d(W, C, C, K, half=True).test()\n",
    "    bm.describe()\n",
    "    print(f'Speedup ratio: {fp16_speed / fp32_speed * 100:.2f}%\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warm up\n",
    "for i in range(1):\n",
    "    torch.cuda.set_device(i)\n",
    "    \n",
    "    A = 2 ** 12\n",
    "    X = torch.randn((A, A)).cuda()\n",
    "    torch.matmul(X, X)\n",
    "    \n",
    "    A = 2 ** 8\n",
    "    B = 2 ** 3\n",
    "    X = torch.randn((1, A, A, A)).cuda()\n",
    "    torch.nn.Conv2d(A, A, B).cuda()(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_CudaDeviceProperties(name='Quadro RTX 5000', major=7, minor=5, total_memory=16095MB, multi_processor_count=48)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100T/100T [00:11<00:00, 9.93TFLOP/s] \n",
      "100%|██████████| 400T/400T [00:08<00:00, 51.8TFLOP/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 4096, 4096])\n",
      "Op: Linear(in_features=4096, out_features=4096, bias=False)\n",
      "128.000GFLOP\n",
      "Speedup ratio: 521.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100T/100T [00:10<00:00, 10.2TFLOP/s] \n",
      "100%|██████████| 400T/400T [00:08<00:00, 51.5TFLOP/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 256, 256, 256])\n",
      "Op: Conv2d(256, 256, kernel_size=(8, 8), stride=(1, 1), bias=False)\n",
      "484.383GFLOP\n",
      "Speedup ratio: 501.91%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    test(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_CudaDeviceProperties(name='Quadro RTX 5000', major=7, minor=5, total_memory=16095MB, multi_processor_count=48)\n"
     ]
    }
   ],
   "source": [
    "device_id = 0\n",
    "torch.cuda.set_device(device_id)\n",
    "print(torch.cuda.get_device_properties(device_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchBenchmarkMatMul(TorchBenchmark):\n",
    "    def __init__(self, a, b, c, bias=False, half=False):\n",
    "        super(TorchBenchmarkMatMul, self).__init__()\n",
    "        \n",
    "        self.half = half\n",
    "        self.dummy = torch.randn((b, a)).cuda()\n",
    "        self.dummy2 = torch.randn((c, b)).cuda()\n",
    "        if half:\n",
    "            self.dummy = self.dummy.half()\n",
    "            self.dummy2 = self.dummy2.half()\n",
    "        self.op = self.dummy2.matmul\n",
    "        self.FLOP = a * b * c * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([4096, 4096])\n",
      "Op: <built-in method matmul of Tensor object at 0x7fad520b8e10>\n",
      "128.000GFLOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400T/400T [00:08<00:00, 51.4TFLOP/s] \n"
     ]
    }
   ],
   "source": [
    "A = 2**12\n",
    "bm = TorchBenchmarkMatMul(A, A, A, half=True)\n",
    "bm.describe()\n",
    "fp16_speed = bm.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 256, 256, 256])\n",
      "Op: Conv2d(256, 256, kernel_size=(8, 8), stride=(1, 1), bias=False)\n",
      "484.383GFLOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400T/400T [00:08<00:00, 53.1TFLOP/s] \n"
     ]
    }
   ],
   "source": [
    "W = 2 ** 8\n",
    "C = 2 ** 8\n",
    "K = 2 ** 3\n",
    "bm = TorchBenchmarkConv2d(W, C, C, K, half=True)\n",
    "bm.describe()\n",
    "fp16_speed = bm.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = 2 ** 12\n",
    "X = torch.randn((A, A)).half().cuda()\n",
    "Y = torch.matmul(X, X)\n",
    "Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = 2 ** 8\n",
    "B = 2 ** 3\n",
    "X = torch.randn((1, A, A, A)).half().cuda()\n",
    "CONV = torch.nn.Conv2d(A, A, B).half().cuda()\n",
    "Y = CONV(X)\n",
    "Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
